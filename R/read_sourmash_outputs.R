#' Read a CSV file output by sourmash compare
#'
#' @param file path to file output by sourmash compare using the with the --csv flag
#' @param sample_to_rownames Boolean indicating whether sample names should be added to the tibble as a column or a rowname
#' @param ... Arguments passed to readr::read_csv()
#'
#' @return A tibble.
#' @export
#'
#' @importFrom rlang .data
#'
#' @examples
#' \dontrun{
#' read_compare_csv("")
#' }
read_compare_csv <- function(file, sample_to_rownames = F, ...){
  if(!file.exists(file)){
    stop("File does not exist. Please provide a valid file path and retry.")
  }
  compare_df <- readr::read_csv(file, ...)
  colnames_compare_df <- colnames(compare_df)
  if(sample_to_rownames == F){
    compare_df <- compare_df %>%
      dplyr::mutate(sample = colnames_compare_df, .before = dplyr::everything())
  } else if(sample_to_rownames == T){
    compare_df <- compare_df %>%
      dplyr::mutate(sample = colnames_compare_df, .before = dplyr::everything()) %>%
      tibble::column_to_rownames("sample")
  }
  return(compare_df)
}

#' Warning handler to suppress warning message that contains "The following named parsers don't match the column names:"
#'
#' @description
#' Function to suppress warning messages produced by `read_gather()` and `read_taxonomy_annotate()` when results were generated by earlier versions of sourmash that didn't output all of the columns output by the current version of sourmash gather.
#'
#' @param w Warning passed to the function by withCallingHandlers()
#'
#' @return The object created by the first argument passed to the function without a warning if the warning contains "The following named parsers don't match the column names:"
#'
#' @examples
#' \dontrun{
#' withCallingHandlers(df <- read_csv(file, col_types = col_types),
#'                     warning = warning_handler))
#' }
warning_handler <- function(w) {
  condition <- conditionMessage(w)
  # create a regular expression to catch the warning that we're missing columns;
  # in this case, we're ok with missing columns because later versions of sourmash gather produce more columns in the gather output than earlier versions
  # we don't want to be warned about that, but we want other warnings to still pass through
  if(grepl("The following named parsers don't match the column names:", condition)) invokeRestart("muffleWarning")
}

#' Read CSV file or files output by sourmash gather
#'
#' @description
#' `read_gather()` reads in one or many CSV files produced by the command line function sourmash taxonomy annotate.
#' Genome matches can be filtered with `intersect_bp_threshold`, whose default value is 0 base pairs.
#'
#' @param file Path to CSV file or files output by sourmash gather.
#' @param intersect_bp_threshold Integer. Gather matches must have an intersect_bp greater than or equal to this value.
#' @param ... Arguments passed to read_csv().
#'
#' @return A tibble.
#' @export
#'
#' @importFrom rlang .data
#'
#' @examples
#' \dontrun{
#' read_gather()
#' }
read_gather <- function(file, intersect_bp_threshold = 0, ...){
  # define column types --
  # this can be auto-generated by running readr::spec_csv("tests/testthat/test1.v450.gather.csv")
  # sourmash gather sometimes adds additional columns with new versions of sourmash,
  # so I decided to explicitly set the column types by column name.
  # this should be compatible with any sourmash gather output produced by any version of sourmash.
  gather_col_types <- readr::cols(intersect_bp = readr::col_double(),
                                  f_orig_query = readr::col_double(),
                                  f_match = readr::col_double(),
                                  f_unique_to_query = readr::col_double(),
                                  f_unique_weighted = readr::col_double(),
                                  average_abund = readr::col_double(),
                                  median_abund = readr::col_double(),
                                  std_abund = readr::col_double(),
                                  filename = readr::col_character(),
                                  name = readr::col_character(),
                                  md5 = readr::col_character(),
                                  f_match_orig = readr::col_double(),
                                  unique_intersect_bp = readr::col_double(),
                                  gather_result_rank = readr::col_double(),
                                  remaining_bp = readr::col_double(),
                                  query_filename = readr::col_character(),
                                  query_name = readr::col_character(),
                                  query_md5 = readr::col_character(),
                                  query_bp = readr::col_double(),
                                  ksize = readr::col_double(),
                                  moltype = readr::col_character(),
                                  scaled = readr::col_double(),
                                  query_n_hashes = readr::col_double(),
                                  query_abundance = readr::col_logical(),
                                  query_containment_ani = readr::col_double(),
                                  match_containment_ani = readr::col_double(),
                                  average_containment_ani = readr::col_double(),
                                  max_containment_ani = readr::col_double(),
                                  potential_false_negative = readr::col_logical(),
                                  n_unique_weighted_found = readr::col_double(),
                                  sum_weighted_found = readr::col_double(),
                                  total_weighted_hashes = readr::col_double())
  if(length(file) > 1){
    if(!all(file.exists(file))){
      stop("Not all files exist. Please provide valid file paths and retry. The Sys.glob() function might help you specify your file paths.")
    }
    # withCallingHandlers catches the specific warnings we want to ignore and doesn't emit them
    # the only warning we want to ignore will start with: "The following named parsers don't match the column names:"
    # allow the function to read multiple files at once
    withCallingHandlers(gather_df <- file %>%
                          purrr::map_dfr(readr::read_csv, col_types = gather_col_types, ...) %>%
                          dplyr::filter(.data$intersect_bp >= intersect_bp_threshold) %>%
                          dplyr::mutate(genome_accession = gsub(" .*", "", .data$name) , .after = "name"),
                        warning = warning_handler)
  } else if(length(file) == 1){
    if(!file.exists(file)){
      stop("File does not exist. Please provide a valid file path and retry.")
    }
    withCallingHandlers(gather_df <- readr::read_csv(file, col_types = gather_col_types, ...) %>%
                          dplyr::filter(.data$intersect_bp >= intersect_bp_threshold) %>%
                          dplyr::mutate(genome_accession = gsub(" .*", "", .data$name) , .after = "name"),
                        warning = warning_handler)
  }
  return(gather_df)
}

#' Read CSV file or files output by sourmash taxonomy annotate
#'
#' @description
#' `read_taxonomy_annotate()` reads in one or many CSV files produced by the command line function sourmash taxonomy annotate.
#' Genome matches can be filtered with `intersect_bp_threshold`, whose default value is 0 base pairs.
#' It adds the column `n_unique_kmers`, the abundance-weighted number of unique k-mers overlapping between a query and its match.
#' Because the output columns from sourmash gather, and by extension sourmash taxonomy, sometimes increase with new versions of sourmash, this function will emit a warning when there are columns missing in the CSV file.
#' This warning can be safely ignored but marks that your results were generated with an earlier version of sourmash, and if you were to re-run sourmash gather, you would have additional information in the output.
#'
#' @param file Path to CSV file or files output by sourmash taxonomy annotate.
#' @param intersect_bp_threshold Integer. Gather matches must have an intersect_bp greater than or equal to this value.
#' @param separate_lineage Boolean. Read in lineage as a single column or separate each taxonomic level to its own column.
#' @param ... Arguments passed to read_csv().
#'
#' @return A tibble.
#' @export
#'
#' @importFrom rlang .data
#'
#' @examples
#' \dontrun{
#' read_taxonomy_annotate()
#' }
read_taxonomy_annotate <- function(file, intersect_bp_threshold = 0, separate_lineage = T, ...){
  # define column types --
  # this can be auto-generated by running readr::spec_csv("tests/testthat/test1.v450.gather.csv") and tacking another coltype on for lineage
  # sourmash gather sometimes adds additional columns with new versions of sourmash,
  # so I decided to explicitly set the column types by column name.
  # this should be compatible with any sourmash gather (and therefore any version of sourmash taxonomy) output produced by any version of sourmash.
  taxonomy_annotate_col_types <- readr::cols(intersect_bp = readr::col_double(),
                                             f_orig_query = readr::col_double(),
                                             f_match = readr::col_double(),
                                             f_unique_to_query = readr::col_double(),
                                             f_unique_weighted = readr::col_double(),
                                             average_abund = readr::col_double(),
                                             median_abund = readr::col_double(),
                                             std_abund = readr::col_double(),
                                             filename = readr::col_character(),
                                             name = readr::col_character(),
                                             md5 = readr::col_character(),
                                             f_match_orig = readr::col_double(),
                                             unique_intersect_bp = readr::col_double(),
                                             gather_result_rank = readr::col_double(),
                                             remaining_bp = readr::col_double(),
                                             query_filename = readr::col_character(),
                                             query_name = readr::col_character(),
                                             query_md5 = readr::col_character(),
                                             query_bp = readr::col_double(),
                                             ksize = readr::col_double(),
                                             moltype = readr::col_character(),
                                             scaled = readr::col_double(),
                                             query_n_hashes = readr::col_double(),
                                             query_abundance = readr::col_logical(),
                                             query_containment_ani = readr::col_double(),
                                             match_containment_ani = readr::col_double(),
                                             average_containment_ani = readr::col_double(),
                                             max_containment_ani = readr::col_double(),
                                             potential_false_negative = readr::col_logical(),
                                             n_unique_weighted_found = readr::col_double(),
                                             sum_weighted_found = readr::col_double(),
                                             total_weighted_hashes = readr::col_double(),
                                             lineage = readr::col_character())

  if(length(file) > 1){
    if(!all(file.exists(file))){
      stop("Not all files exist. Please provide valid file paths and retry. The Sys.glob() function might help you specify your file paths.")
    }
    # withCallingHandlers catches the specific warnings we want to ignore and doesn't emit them
    # the only warning we want to ignore will start with: "The following named parsers don't match the column names:"
    # allow the function to read multiple files at once
    withCallingHandlers(taxonomy_annotate_df <- file %>%
                          purrr::map_dfr(readr::read_csv, col_types = taxonomy_annotate_col_types, ...) %>%
                          dplyr::filter(.data$intersect_bp >= intersect_bp_threshold) %>%
                          dplyr::mutate(n_unique_kmers = (.data$unique_intersect_bp / .data$scaled) * .data$average_abund) %>% # calculate the number of uniquely matched k-mers
                          dplyr::mutate(genome_accession = gsub(" .*", "", .data$name) , .after = "name"),
                        warning = warning_handler)
  } else if(length(file) == 1){
    if(!file.exists(file)){
      stop("File does not exist. Please provide a valid file path and retry.")
    }
    # withCallingHandlers catches the specific warnings we want to ignore and doesn't emit them
    # the only warning we want to ignore will start with: "The following named parsers don't match the column names:"
    withCallingHandlers(taxonomy_annotate_df <- readr::read_csv(file, col_types = taxonomy_annotate_col_types, ...) %>%
                          dplyr::filter(.data$intersect_bp >= intersect_bp_threshold) %>%
                          dplyr::mutate(n_unique_kmers = (.data$unique_intersect_bp / .data$scaled) * .data$average_abund) %>% # calculate the number of uniquely matched k-mers
                          dplyr::mutate(genome_accession = gsub(" .*", "", .data$name) , .after = "name"),
                        warning = warning_handler)
  }
  if(separate_lineage == T){
    taxonomy_annotate_df <- taxonomy_annotate_df %>%
      tidyr::separate(.data$lineage, into = c("domain", "phylum", "class", "order", "family", "genus", "species", "strain"), sep = ";", remove = F, fill = "right")
  }
  return(taxonomy_annotate_df)
}

#' Calculate the scaled value for a signature from the max_hash value
#'
#' @param sig_max_hash Max hash value in a signature.
#'
#' @return Integer; a scaled value
#'
get_scaled_for_max_hash <- function(sig_max_hash){
  # sourmash uses the 64-bit hash space of MurmurHash only
  # this is 2 ** 64 - 1 in hexadecimal
  # https://github.com/sourmash-bio/sourmash/blob/a8bd648f60d4e73f3f6bc55cbe70bd174da4a399/src/sourmash/minhash.py#L40
  MINHASH_MAX_HASH = 0xFFFFFFFFFFFFFFFF
  scaled <- round( MINHASH_MAX_HASH / sig_max_hash, digits = 0)
  scaled
}

#' Read one sourmash signature into a dataframe
#'
#' @description
#' `read_signature_one` reads one signature into a data frame.
#' It's mostly a dummy function, but breaking it out this way allows one or many files to be passed to `read_signature`.
#'
#' @param file Path to signature (json) file output by sourmash sketch (previously sourmash compute).
#' @param compliant Boolean indicating whether signature columns should be compliant; the json fields changed across versions of sourmash. This may drop deprecated columns like 'type' but will allow you to bind many signatures into a single data frame even if they were sketched with different versions of sourmash.
#'
#' @return A tibble.
#' @export
#'
#' @importFrom rlang .data
#'
#' @examples
#' \dontrun{
#' read_signature("tests/testthat/SRR18071810.sig")
#' }
read_signature_one <- function(file, compliant = TRUE){
  if(!file.exists(file)){
    stop("File does not exist. Please provide a valid file path and retry.
         If you are trying to pass multiple files to the read_signature() function, the Sys.glob() function might help you specify your file paths.")
  }

  # read in the signature json file to a data frame and calculate the scaled value
  sig_df <- jsonlite::fromJSON(file) %>%
    tidyr::unnest(tidyselect::one_of("signatures")) %>%
    tidyr::unnest(tidyselect::any_of(c("mins", "abundances"))) # any_of allows abundances to be present in signature or not

  # if max_hash is 0, then num was set
  # if num was set, scaled does not need to be calculated
  # max_hash should be the same between all sketches in a sig; I don't think they can be calculated any other way
  if(unique(sig_df$max_hash) != 0){
    sig_df <- sig_df %>%
      dplyr::mutate(scaled = get_scaled_for_max_hash(.data$max_hash)) # calculate the scaled value from max_hash
  }

  if(compliant == TRUE) {
    # define columns that should be selected if compliant = TRUE
    # these are accurate as of sourmash version 4.
    sourmashv4_sig_fields <- c('class', 'email', 'hash_function', 'filename', 'name',
                               'license', 'num', 'ksize', 'seed', 'max_hash', 'scaled', 'mins',
                               'md5sum', 'abundances', 'molecule', 'version')
    sig_df <- sig_df %>%
      dplyr::select(tidyselect::any_of(sourmashv4_sig_fields))
  }

  return(sig_df)
}

#' Read sourmash signature or signatures into a dataframe
#'
#' @description
#' `read_signature()` reads in one or many signatures (JSON files) produced by the command line function sourmash sketch (previously sourmash compute).
#'
#' @param file Path to signature (json) file or files output by sourmash sketch (previously sourmash compute).
#' @param compliant Boolean indicating whether signature columns should be compliant; the json fields changed across versions of sourmash. This may drop deprecated columns like 'type' but will allow you to bind many signatures into a single data frame even if they were sketched with different versions of sourmash.
#'
#' @return A tibble.
#' @export
#'
#' @examples
#' \dontrun{
#' read_signature()
#' }
read_signature <- function(file, compliant = TRUE){
  if(length(file) > 1) {
    sig_df <- file %>%
      purrr::map_dfr(read_signature_one, compliant = compliant)
  } else if(length(file) == 1) {
    sig_df <- read_signature_one(file, compliant = compliant)
  }
  return(sig_df)
}
